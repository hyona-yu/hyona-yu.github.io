---
layout: post
title: 'Human Activity Recognition(HAR) 논문 리뷰'
date: 2020-07-27
author: hyona
color: rgb(255,210,32)
cover: 'http://on2171g4d.bkt.clouddn.com/jekyll-banner.png'
tags: machine learning, HAR, Human Activity Recognition, deep learning
---

> Human Activity Recognition 논문을 읽어보자!

### [Human Activity Recognition: A Survey](https://www.sciencedirect.com/science/article/pii/S1877050919310166)   

굉장히 짧은 survey 논문! Deep Learning과 Pattern Recognition(SVM 등)에 나오는 machine learning을 비교 분석했다. 거의 모든 기법에 공통으로 filtering과 같은 전처리가 들어갔고, sensor 기반은 센서가 많을 수록 더 좋은 결과를 보여줬다. 약간의 중지, 중단이 있을 경우에 RNN과 LSTM을 썼다.

HAR에서는 camera based와 sensor based로 크게 나눌 수 있는데, camera를 쓰는 Vision 방법일 경우 군중이 있을 경우 activity recognition을 특정하기 힘들고, 다수의 관찰자를 특정하기 어렵다.






### [A Deep Learning Method for Complex Human Activity Recognition Using Virtual Wearable Sensors](https://arxiv.org/abs/2003.01874)
 Real-scene에 적용할 수 있는 HAR 기법을 제안하는 논문이다. Off-line에서는 extract feature(특징 추출)를, on-line에서는 transfer learning(전이 학습)을 적용하여 IMU 센서 데이터를 기반으로 한다.   

 SVM, RF과 같은 전통적인 머신러닝 방법은 특징 선별 등의 memory, time consuming이 많다. 최근에는 딥러닝인 CNN, LSTM을 이용한 기법이 HAR에 많이 사용되는 편이다.    

 HAR dataset들을 살펴보면 주로 real world와 다르고, 한 개의 IMU 센서만 쓰기 때문에 정교한 활동을 인지하는 데에 어려움이 있다. 그래서 본문에서 사용한 데이터는 AMASS로, motion capture(Mocap) dataset이다.   

AMASS 의 가상 IMU data를 사용하기에 앞서 SMPL 모델(3D human body)에 적용할 수 있도록 전처리를 한다. Dataset에 1100개 가량의 motion이 있으므로 분류해서 labeling 해주자. 전처리를 잘하자! 이거 하고 닸더니 real IMU로 test했을 때 차이가 거의 없었다.
